# -*- coding: utf-8 -*-
"""logi_bias_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nYwSvZJDJupLDJTumGuK4DsAoGh65M-e
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/hiring_audit_data_2026.csv')

df

df.info()

df.isnull().sum().sum()

df.duplicated().sum()

"""# **Bias Discovery**"""

#calculate hiring rate by gender
bias_check = df.groupby('Gender')['Shortlisted'].mean()

print(f'Hiring Rates :\n{bias_check}')

#calculate Adverse Impact ratio
air = bias_check['Female']/bias_check['Male']
print(f'Initial Adverse Impact Ratio:{air:.2f}')    #as AIR is coming 0.62 which is bias it should be not less than 0.8

#outliers
for col in df.columns :
  if (df[col].dtype!='object'):
    sns.boxplot(df[col])
    plt.xlabel(col)
    plt.show()

out_list=['Technical_Score','Projects_done','Career_Gap_Months']
for col in out_list:
  Q1=df[col].quantile(0.25)
  Q3=df[col].quantile(0.75)

  IQR= Q3-Q1

  LB = Q1-1.5*(IQR)
  UB = Q3+1.5*(IQR)

  df=df[(df[col]>=LB) & (df[col]<=UB)]

for col in df.columns :
  if (df[col].dtype!='object'):
    sns.boxplot(df[col])
    plt.xlabel(col)
    plt.show()

#label encoding
from sklearn.preprocessing import LabelEncoder

LE = LabelEncoder()

for col in df.columns:
  if df[col].dtype=='object':
    df[col]=LE.fit_transform(df[col])

df

df["Shortlisted"].value_counts()

df.info()

bias_check = df.groupby('Gender')['Shortlisted'].mean()
print(f'Hiring Rates :\n{bias_check}')

air = bias_check[0]/bias_check[1]
print(f'Initial Adverse Impact Ratio:{air:.3f}')

#VIf
x=df.drop('Shortlisted',axis= 1)
y=df['Shortlisted']

x

y

vif_data=pd.DataFrame()

vif_data

x.columns

vif_data['Features']=x.columns

vif_data

from statsmodels.stats.outliers_influence import variance_inflation_factor

vif_value=[]
for i in range (len(x.columns)):
  vif=variance_inflation_factor(x.values,i)
  vif_value.append(vif)

vif_data['Vif_Values']=vif_value

vif_data

x.drop('KPI_Completion_Pct',axis=1,inplace=True)

vif_data=pd.DataFrame()
vif_data['Features']=x.columns

vif_value=[]
for i in range (len(x.columns)):
  vif=variance_inflation_factor(x.values,i)
  vif_value.append(vif)

vif_data['Vif_Values']=vif_value

vif_data

x.drop('Technical_Score',axis=1,inplace=True)

vif_data=pd.DataFrame()
vif_data['Features']=x.columns

vif_value=[]
for i in range (len(x.columns)):
  vif=variance_inflation_factor(x.values,i)
  vif_value.append(vif)

vif_data['Vif_Values']=vif_value

vif_data

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.80)

x_train

from imblearn.over_sampling import SMOTE

x=df[["Gender","Projects_done", "Career_Gap_Months"]]
y=df["Shortlisted"]

x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.80)

smote=SMOTE()

x_train_new,y_train_new=smote.fit_resample(x_train,y_train)

from sklearn.linear_model import LogisticRegression

LR=LogisticRegression()

LR.fit(x_train_new,y_train_new)

y_pred=LR.predict(x_test)

from sklearn.metrics import f1_score

f1_score(y_test,y_pred)*100

bias_check = df.groupby('Gender')['Shortlisted'].mean()
print(f'Hiring Rates :\n{bias_check}')

air = bias_check[0]/bias_check[1]
print(f'Initial Adverse Impact Ratio:{air:.3f}')

# Visualization
# 1) The fairness gap (Air Comparison)

# Data from the result
labels = ['Initial Data', 'Post-Audit Model']
air_values = [0.62, 0.707]
plt.figure(figsize=(8, 5))
colors = ['#ff9999', '#66b3ff']
bars = plt.bar(labels, air_values, color=colors)

# Adding the 0.80 'Legal frontier' Line

plt.axhline(y=0.80, color='r', linestyle='--', label='80% Rule (Legal Threshold)')

plt.title('Fairness Audit: Adverse Impact Ratio (AIR)', fontsize=14)
plt.ylabel('AIR Score')
plt.ylim(0, 1)
plt.legend()

# Adding text labels on bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f'{yval}', ha='center', va='bottom', fontweight='bold')

plt.show()

# The Multicollinearity 'HeatMap'

# select final features(after dropping)

final_features =df[['Projects_done','Career_Gap_Months','Gender']]
plt.figure(figsize=(10,6))
sns.heatmap(final_features.corr(),annot=True,cmap='coolwarm',fmt='.2f')
plt.title('Feature Correlation Matrix (Post-VIF Audit)',fontsize=14)
plt.show()

# Extracting coefficients from your Logistic Regression
importance = LR.coef_[0]
feature_names = x.columns

# Create a dataframe for plotting
feat_importances = pd.Series(importance, index=feature_names)

plt.figure(figsize=(10, 6))
feat_importances.nlargest(10).plot(kind='barh', color='#4CAF50')
plt.title('Final Model: What Drives Hiring Decisions?', fontsize=14)
plt.xlabel('Coefficient Magnitude (Weight)')
plt.show()